hist(diet.df$weight.lost)
summary(aov(diet.df$weight.lost~diet.df$Diet))
summary.lm(aov(diet.df$weight.lost~diet.df$Diet))
plot(aov(diet.df$weight.lost~diet.df$Diet))
aggregate(diet.df$weight.lost~diet.df$Diet, FUN="mean")
ggplot(diet.df, aes(x=Diet, y=weight.lost)) + geom_boxplot() + theme_classic()
model2<-lm(diet.df$weight.lost~diet.df$Diet+diet.df$Age)
summary(model2)
plot(model2)
model3<-lm(diet.df$weight.lost~diet.df$Diet+ diet.df$gender + diet.df$pre.weight)
summary(model3)
diet.df$diet.ind<-ifelse(diet.df$Diet=="3", "3", "1 or 2")
table(diet.df$diet.ind)
model3<-aov(diet.df$weight.lost~diet.df$diet.ind)
summary.lm(model3)
diet2.df<-subset(diet.df, !is.na(diet.df$gender))
model.gender.aov<-aov(diet2.df$weight.lost~diet2.df$gender)
summary.lm(model.gender.aov)
# This is an R code chunk
print("Goodbye cruel world")
# This is an R code chunk
print("Goodbye cruel world")
z <- 3
z <- z * 17
print(z)
# Fetch the raw data
# Read the csv file into a new data frame called surveyDF
surveyFileName <- "https://raw.githubusercontent.com/mjshepperd/CS5702-Data/master/CS5702JoiningSurvey_2020.csv"
surveyDF <- read.csv(surveyFileName, header = TRUE, stringsAsFactors = FALSE)
# Clean up surveyDF column names
names(surveyDF)  # The names() function returns all the dataframe column names
# Choose shorter, clearer names
names(surveyDF)[2] <- "MSc"
names(surveyDF)[3] <- "StudyMode"
names(surveyDF)[4] <- "Background"
names(surveyDF)[5] <- "Motivation"
names(surveyDF)[6] <- "StatsKnowl"
names(surveyDF)[7] <- "ProgKnowl"
names(surveyDF)[8] <- "ProgLangs"
names(surveyDF)[9] <- "Excite"
names(surveyDF)[10] <- "Concern"
# Fetch the raw data
# Read the csv file into a new data frame called surveyDF
surveyFileName <- "https://raw.githubusercontent.com/mjshepperd/CS5702-Data/master/CS5702JoiningSurvey_2020.csv"
surveyDF <- read.csv(surveyFileName, header = TRUE, stringsAsFactors = FALSE)
print(surveyDF)
z <- 3
z <- z * 17
print(z)
# A *very* simple way to check for missing observations in our data frame
# using the is.na() function
is.na(surveyDF)
# Examine the data frame structure
str(surveyDF)
# Shorten the MSc titles (for convenience)
surveyDF[surveyDF=="MSc Artificial Intelligence (AI)"] <- "AI"
surveyDF[surveyDF=="MSc Data Science Analytics (DSA)"] <- "DSA"
# Using the summary() function on the numeric variables
summary(surveyDF$StatsKnowl)
summary(surveyDF$ProgKnowl)
# And easier to visualise
# I superimpose the a probability density plot over the histogram
hist(surveyDF$StatsKnowl,
main="Histogram of Perceived Statistical Knowledge",
xlab="Score (1 = low, 10 = high)",
col="darkgray",
xlim=c(1,10),
breaks=1:10,
prob = TRUE
)
library("ggplot2", lib.loc="~/R/win-library/4.0")
# Using the summary() function on the numeric variables
summary(surveyDF$StatsKnowl)
summary(surveyDF$ProgKnowl)
# And easier to visualise
# I superimpose the a probability density plot over the histogram
hist(surveyDF$StatsKnowl,
main="Histogram of Perceived Statistical Knowledge",
xlab="Score (1 = low, 10 = high)",
col="darkgray",
xlim=c(1,10),
breaks=1:10,
prob = TRUE
)
# Shorten the MSc titles (for convenience)
surveyDF[surveyDF=="MSc Artificial Intelligence (AI)"] <- "AI"
surveyDF[surveyDF=="MSc Data Science Analytics (DSA)"] <- "DSA"
# Using the summary() function on the numeric variables
summary(surveyDF$StatsKnowl)
summary(surveyDF$ProgKnowl)
# And easier to visualise
# I superimpose the a probability density plot over the histogram
hist(surveyDF$StatsKnowl,
main="Histogram of Perceived Statistical Knowledge",
xlab="Score (1 = low, 10 = high)",
col="darkgray",
xlim=c(1,10),
breaks=1:10,
prob = TRUE
)
# Use the table() function to produce tables of frequency counts
table(surveyDF$MSc)
table(surveyDF$StudyMode)
table(surveyDF$Background)
# Fetch the raw data
# Read the csv file into a new data frame called surveyDF
surveyFileName <- "https://raw.githubusercontent.com/mjshepperd/CS5702-Data/master/CS5702JoiningSurvey_2020.csv"
surveyDF <- read.csv(surveyFileName, header = TRUE, stringsAsFactors = FALSE)
print(surveyDF)
# Fetch the raw data
# Read the csv file into a new data frame called surveyDF
surveyFileName <- "https://raw.githubusercontent.com/mjshepperd/CS5702-Data/master/CS5702JoiningSurvey_2020.csv"
surveyDF <- read.csv(surveyFileName, header = TRUE, stringsAsFactors = FALSE)
print(surveyDF)
view(surveyDF)
View(surveyDF)
# Fetch the raw data
# Read the csv file into a new data frame called surveyDF
surveyFileName <- "https://raw.githubusercontent.com/mjshepperd/CS5702-Data/master/CS5702JoiningSurvey_2020.csv"
surveyDF <- read.csv(surveyFileName, header = TRUE, stringsAsFactors = FALSE)
print(surveyDF)
surveyDF[3,2]
print(survey$Msc)
print(surveyDF$Which.MSc.will.you.be.studying.)
# Clean up surveyDF column names
names(surveyDF)  # The names() function returns all the dataframe column names
# Choose shorter, clearer names
names(surveyDF)[2] <- "MSc"
names(surveyDF)[3] <- "StudyMode"
names(surveyDF)[4] <- "Background"
names(surveyDF)[5] <- "Motivation"
names(surveyDF)[6] <- "StatsKnowl"
names(surveyDF)[7] <- "ProgKnowl"
names(surveyDF)[8] <- "ProgLangs"
names(surveyDF)[9] <- "Excite"
names(surveyDF)[10] <- "Concern"
print(surveyDF$[1])
print(surveyDF$MSc)
# Using the summary() function on the numeric variables
summary(surveyDF$StatsKnowl)
summary(surveyDF$ProgKnowl)
# And easier to visualise
# I superimpose the a probability density plot over the histogram
hist(surveyDF$StatsKnowl,
main="Histogram of Perceived Statistical Knowledge",
xlab="Score (1 = low, 10 = high)",
col="darkgray",
xlim=c(1,10),
breaks=1:10,
prob = TRUE
)
lines(density(surveyDF$StatsKnowl), col = "red")
hist(surveyDF$ProgKnowl,
main="Histogram of Perceived Programming Knowledge",
xlab="Score (1 = low, 10 = high)",
col="darkgray",
xlim=c(1,10),
breaks=1:10,
prob = TRUE
)
lines(density(surveyDF$ProgKnowl), col = "red")
# Alternatively we can use boxplots
boxplot(surveyDF$StatsKnowl, surveyDF$ProgKnowl)
# Use the table() function to produce tables of frequency counts
table(surveyDF$MSc)
table(surveyDF$StudyMode)
table(surveyDF$Background)
# Use the table() function to produce tables of frequency counts
table(surveyDF$MSc)
table(surveyDF$StudyMode)
table(surveyDF$Background)
# This is an example of a 2-d table of frequencies.
table(surveyDF$Background, surveyDF$MSc)
# and if we want marginal totals wrap table() with the addmargins() function
addmargins(table(surveyDF$Background, surveyDF$MSc))
# and if you want proportions then wrap with prop.table()
prop.table(table(surveyDF$Background, surveyDF$MSc))
# Convert MSc into a factor, i.e., use as a categorical variable
surveyDF$MSc <- as.factor(surveyDF$MSc)
# Compare the different distributions of values using a boxplot for each value of the factor MSc.
# Since there are 2 courses (AI and DSA) this produces 2 boxplots of StatsKnowl and we can see
# if there are any differences
boxplot(surveyDF$StatsKnowl ~ surveyDF$MSc,
notch = TRUE,            # Shows the 95% confidence intervals
horizontal = TRUE,
xlab = "Statistical understanding",
ylab = "")
# Side by side boxplots of ProgKnowl separated by the factor MSc.
boxplot(surveyDF$ProgKnowl ~ surveyDF$MSc,
notch = TRUE,           # Shows the 95% confidence intervals
horizontal = TRUE,
xlab = "Programming understanding",
ylab = "")
# To extract all the words into a single character string you need the
# paste() function with the collapse option.
words <- paste(surveyDF$Excite, collapse = " ")
# Display the words
words
# Save the words in a text file as input to a word cloud generator
# You can change the file name
# NB This will overwrite the previous contents (if any)
fileName <- file("MyWords.txt")
writeLines(words, fileName)
close(fileName)
# Compute sales income for Martin's book
price <- 10                                     # assume price is 10 UKP per book copy
numberStudents <- 100                           # number of students in the class
recommend <- 0.5                                # proportion of students who recommend the book
sales <- numberStudents * (1 + recommend)
income <- sales * price
outputMsg <- paste("Martin will earn:", income) # format a readable string with the paste function
print(outputMsg, quote = FALSE)                 # output the concatenated string without quotes
# Your extended code needs to go here
# If a package is installed, it will be loaded and missing package(s) will be installed
# from CRAN and then loaded.
# The packages we need are:
packages = c("tidyverse", "devtools")
# Load the package or install and load it
package.check <- lapply(
packages,
FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x, dependencies = TRUE)
library(x, character.only = TRUE)
}
}
)
install_github("joachim-gassen/tidycovid19")
#Download the data into a data frame called cv.df using the
#download_jhu_csse_covid19_data() function from the {tidycovid19} package.
#
cv.df <- download_jhu_csse_covid19_data(cached = TRUE)
install.packages("tidycovid")
# If a package is installed, it will be loaded and missing package(s) will be installed
# from CRAN and then loaded.
# The packages we need are:
packages = c("tidyverse", "devtools")
# Load the package or install and load it
package.check <- lapply(
packages,
FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x, dependencies = TRUE)
library(x, character.only = TRUE)
}
}
)
install_github("tidycovid19")
# If a package is installed, it will be loaded and missing package(s) will be installed
# from CRAN and then loaded.
# The packages we need are:
packages = c("tidyverse", "devtools")
# Load the package or install and load it
package.check <- lapply(
packages,
FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x, dependencies = TRUE)
library(x, character.only = TRUE)
}
}
)
install_github("https://github.com/joachim-gassen/tidycovid19.git")
library(tidyverse)
library(tidycovid19)
library(zoo)
library(tidycovid19)
#Download the data into a data frame called cv.df using the
#download_jhu_csse_covid19_data() function from the {tidycovid19} package.
#
cv.df <- download_jhu_csse_covid19_data(cached = TRUE)
# select only the UK data
cv.uk.df <- subset(cv.df, iso3c=="GBR")
head(cv.uk.df)
tail(cv.uk.df)
# Compute new deaths as the data shows cumulative deaths
cv.uk.df$new.d[2:nrow(cv.uk.df)] <- tail(cv.uk.df$deaths, -1) - head(cv.uk.df$deaths, -1)
cv.uk.df$new.d[1] <- 0     # Add zero for first row
# Compute new infections
cv.uk.df$new.i[2:nrow(cv.uk.df)] <- tail(cv.uk.df$confirmed, -1) - head(cv.uk.df$confirmed, -1)
cv.uk.df$new.i[1] <- 0     # Add zero for first row
# NB a small span value (<1) makes the loess smoother more wiggly!
ggplot(data = cv.uk.df, aes(x = date, y = new.d)) +
geom_line(color = "skyblue", size = 0.6) +
ylim(0,1200) +
stat_smooth(color = "darkorange", fill = "darkorange", method = "loess", span = 0.2) +
ggtitle("Daily additional deaths in the UK due to covid-19") +
xlab("Date") + ylab("Daily new deaths")
ggsave("cv19_UK_deathrate.png")
ggplot(data = cv.uk.df, aes(x = date, y = new.i)) +
geom_line(color = "skyblue", size = 0.6) +
scale_y_continuous(trans = "log10") +
stat_smooth(color = "darkorange", fill = "darkorange", method = "loess") +
ggtitle("Daily new infections in the UK from covid-19") +
xlab("Date") + ylab("Daily new infections")
ggsave("cv19_UK_infectionrate.png")
is.integer(cv.uk.df$new.i)
cv.uk.df$new.i <- as.integer(cv.uk.df$new.i)
cv.uk.df$new.i <- as.integer(cv.uk.df$new.i)
cv.uk.df$recovered[236] <- 0
# Compute new deaths as the data shows cumulative deaths
cv.uk.df$new.d[2:nrow(cv.uk.df)] <- tail(cv.uk.df$deaths, -1) - head(cv.uk.df$deaths, -1)
cv.uk.df$new.d[1] <- 0     # Add zero for first row
# Compute new infections
cv.uk.df$new.i[2:nrow(cv.uk.df)] <- tail(cv.uk.df$confirmed, -1) - head(cv.uk.df$confirmed, -1)
cv.uk.df$new.i[1] <- 0     # Add zero for first row
# NB a small span value (<1) makes the loess smoother more wiggly!
ggplot(data = cv.uk.df, aes(x = date, y = new.d)) +
geom_line(color = "skyblue", size = 0.6) +
ylim(0,1200) +
stat_smooth(color = "darkorange", fill = "darkorange", method = "loess", span = 0.2) +
ggtitle("Daily additional deaths in the UK due to covid-19") +
xlab("Date") + ylab("Daily new deaths")
ggsave("cv19_UK_deathrate.png")
ggplot(data = cv.uk.df, aes(x = date, y = new.i)) +
geom_line(color = "skyblue", size = 0.6) +
scale_y_continuous(trans = "log10") +
stat_smooth(color = "darkorange", fill = "darkorange", method = "loess") +
ggtitle("Daily new infections in the UK from covid-19") +
xlab("Date") + ylab("Daily new infections")
ggsave("cv19_UK_infectionrate.png")
# We need to read from the {validate} package in the R library into memory
# If you haven't installed it, then you need to run install.packages("validate")
# but do this only once.
library(validate)
install.packages("validate")
# We need to read from the {validate} package in the R library into memory
# If you haven't installed it, then you need to run install.packages("validate")
# but do this only once.
library(validate)
# Store the GitHub address in fname
fname <- "https://raw.githubusercontent.com/mjshepperd/CS5702-Data/master/CS5702_W3_NASAexample.csv"
defectDF <- read.csv(fname, header = TRUE, fileEncoding = 'UTF-8-BOM')
checkResults <- check_that(defectDF, NUMBER_OF_LINES >= LOC_BLANK + LOC_COMMENTS +
LOC_TOTAL)
checkResults
# Take the output from check_that() and turn it into a dataframe f
# or easier manipulation
checkResultsDF <- as.data.frame(checkResults)
problems <- subset(checkResultsDF, value==FALSE)
# Build a rule set (of 2 rules) named rules
rules <- validator(R1 = LOC_CODE_AND_COMMENT >= 0,
R2 = NUMBER_OF_LINES >= (LOC_BLANK + LOC_COMMENTS + LOC_TOTAL))
# Now apply our rule set
checkResults <- confront(defectDF,rules)
checkResultsDF <- as.data.frame(checkResults)
ProbResultsDF <- subset(checkResultsDF, value=="FALSE")
# Code to select the student specific team combination.
# Feel free to change it including the data frame name.
#
# my.2teams.df <- subset(analysis.data, teamID.x=="???" | teamID.x=="???")
BOSLAA = subset(CS5801.data, teamID.x == "BOS" | teamID.x=="LAA")
load("~/R/CoronaShmorona/MA/Ass/CS5801_data.rda")
# Code to select the student specific team combination.
# Feel free to change it including the data frame name.
#
# my.2teams.df <- subset(analysis.data, teamID.x=="???" | teamID.x=="???")
BOSLAA = subset(CS5801.data, teamID.x == "BOS" | teamID.x=="LAA")
BOS = subset(CS5801.data, teamID.x == "BOS")
LAA = subset(CS5801.data, teamID.x == "LAA")
# Code to select the student specific team combination.
# Feel free to change it including the data frame name.
#
# my.2teams.df <- subset(analysis.data, teamID.x=="???" | teamID.x=="???")
BOSLAA = subset(CS5801.data, teamID.x == "BOS" | teamID.x=="LAA")
BOS = subset(CS5801.data, teamID.x == "BOS")
LAA = subset(CS5801.data, teamID.x == "LAA")
League = CS5801.data
summary(League)
summary(BOSLAA)
summary(BOS)
summary(LAA)
# Code to select the student specific team combination.
# Feel free to change it including the data frame name.
#
# my.2teams.df <- subset(analysis.data, teamID.x=="???" | teamID.x=="???")
# Only the two teams need to be separated at this stage, but I also decivded to have subsets including only one team each. The reason is that
BOSLAA = subset(CS5801.data, teamID.x == "BOS" | teamID.x=="LAA")
BOS = subset(CS5801.data, teamID.x == "BOS")
LAA = subset(CS5801.data, teamID.x == "LAA")
League = CS5801.data
summary(League)
summary(BOSLAA)
summary(BOS)
summary(LAA)
col(League)
# Code to select the student specific team combination.
# Feel free to change it including the data frame name.
#
# my.2teams.df <- subset(analysis.data, teamID.x=="???" | teamID.x=="???")
# Only the two teams need to be separated at this stage, but I also decivded to have subsets including only one team each. The reason is that
BOSLAA = subset(CS5801.data, teamID.x == "BOS" | teamID.x=="LAA")
BOS = subset(CS5801.data, teamID.x == "BOS")
LAA = subset(CS5801.data, teamID.x == "LAA")
League = CS5801.data
summary(League)
summary(BOSLAA)
summary(BOS)
summary(LAA)
plot(League)
load("~/R/CoronaShmorona/MA/Ass/CS5801_data.rda")
View(CS5801.data)
defectDF <- read.csv(fname, header = TRUE, fileEncoding = 'UTF-8-BOM')
# We need to read from the {validate} package in the R library into memory
# If you haven't installed it, then you need to run install.packages("validate")
# but do this only once.
library(validate)
# Store the GitHub address in fname
fname <- "https://raw.githubusercontent.com/mjshepperd/CS5702-Data/master/CS5702_W3_NASAexample.csv"
defectDF <- read.csv(fname, header = TRUE, fileEncoding = 'UTF-8-BOM')
defectDF <- read.csv("https://raw.githubusercontent.com/mjshepperd/CS5702-Data/master/CS5702_W3_NASAexample.csv", header = TRUE, fileEncoding = 'UTF-8-BOM')
# We need to read from the {validate} package in the R library into memory
# If you haven't installed it, then you need to run install.packages("validate")
# but do this only once.
library(validate)
# Store the GitHub address in fname
fname <- "https://raw.githubusercontent.com/mjshepperd/CS5702-Data/master/CS5702_W3_NASAexample.csv"
defectDF <- read.csv(fname, header = TRUE, fileEncoding = 'UTF-8-BOM')
checkResults <- check_that(defectDF, NUMBER_OF_LINES >= LOC_BLANK + LOC_COMMENTS +
LOC_TOTAL)
checkResults
checkResults <- check_that(defectDF, NUMBER_OF_LINES >= LOC_BLANK + LOC_COMMENTS +
LOC_TOTAL)
checkResults
checkResults <- check_that(League, NUMBER_OF_LINES >= LOC_BLANK + LOC_COMMENTS +
LOC_TOTAL)
checkResults
checkResults <- check_that(BOSLAA, NUMBER_OF_LINES >= LOC_BLANK + LOC_COMMENTS +
LOC_TOTAL)
checkResults
View(defectDF)
View(defectDF)
checkResults <- check_that(BOSLAA, NUMBER_OF_LINES >= G + R + H)
checkResults
checkResults <- check_that(LAA, NUMBER_OF_LINES >= G + R + H)
checkResults
checkResults <- check_that(BOS, NUMBER_OF_LINES >= G + R + H)
checkResults
checkResults <- check_that(BOS, AB >= G + R + H)
checkResults
checkResults <- check_that(BOS, AB >= G + R + H)
checkResults
checkResults <- check_that(League, AB >= G + R + H)
checkResults
checkResults <- check_that(BOSLAA, AB >= G + R + H)
checkResults
checkResults <- check_that(LAA, AB >= G + R + H)
checkResults
checkResults <- check_that(BOS, AB >= G + R + H)
checkResults
# Take the output from check_that() and turn it into a dataframe f
# or easier manipulation
checkResultsDF <- as.data.frame(checkResults)
problems <- subset(checkResultsDF, value==FALSE)
# Build a rule set (of 2 rules) named rules
rules <- validator(R1 = LOC_CODE_AND_COMMENT >= 0,
R2 = NUMBER_OF_LINES >= (LOC_BLANK + LOC_COMMENTS + LOC_TOTAL))
# Now apply our rule set
checkResults <- confront(defectDF,rules)
checkResultsDF <- as.data.frame(checkResults)
ProbResultsDF <- subset(checkResultsDF, value=="FALSE")
# We need to read from the {validate} package in the R library into memory
# If you haven't installed it, then you need to run install.packages("validate")
# but do this only once.
library(validate)
# Store the GitHub address in fname
fname <- "https://raw.githubusercontent.com/mjshepperd/CS5702-Data/master/CS5702_W3_NASAexample.csv"
checkleague <- check_that(League, 968 >= teamid.x)
checkResults
checkleague <- check_that(League, 968 >= G)
checkResults
checkleague <- check_that(League, 968 >= salary)
checkResults
checkleague <- check_that(League, 40 >= salary)
checkResults
checkleague <- check_that(League, 986 >= salary)
checkleague
checkleague <- check_that(League, 968 >= salary)
checkleague
checkleague <- check_that(League, 968 >= teamid.x)
checkleague
checkleague <- check_that(League, 968 >= teamID.x)
checkleague
View(problems)
checkResults <- check_that(defectDF, NUMBER_OF_LINES >= LOC_BLANK + LOC_COMMENTS +
LOC_TOTAL)
checkResults
# Take the output from check_that() and turn it into a dataframe f
# or easier manipulation
checkResultsDF <- as.data.frame(checkResults)
problems <- subset(checkResultsDF, value==FALSE)
View(problems)
# Take the output from check_that() and turn it into a dataframe f
# or easier manipulation
checkResultsDF <- as.data.frame(checkResults)
problems <- subset(checkResultsDF, value==FALSE)
# Build a rule set (of 2 rules) named rules
rules <- validator(R1 = LOC_CODE_AND_COMMENT >= 0,
R2 = NUMBER_OF_LINES >= (LOC_BLANK + LOC_COMMENTS + LOC_TOTAL))
# Now apply our rule set
checkResults <- confront(defectDF,rules)
checkResultsDF <- as.data.frame(checkResults)
View(checkResultsDF)
View(problems)
# Build a rule set (of 2 rules) named rules
rules <- validator(R1 = LOC_CODE_AND_COMMENT >= 0,
R2 = NUMBER_OF_LINES >= (LOC_BLANK + LOC_COMMENTS + LOC_TOTAL))
# Now apply our rule set
checkResults <- confront(defectDF,rules)
checkResultsDF <- as.data.frame(checkResults)
ProbResultsDF <- subset(checkResultsDF, value=="FALSE")
View(ProbResultsDF)
